//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-27506705
// Cuda compilation tools, release 10.2, V10.2.89
// Based on LLVM 3.4svn
//

.version 6.5
.target sm_30
.address_size 64

	// .globl	_Z4add2PdPKd

.visible .entry _Z4add2PdPKd(
	.param .u64 _Z4add2PdPKd_param_0,
	.param .u64 _Z4add2PdPKd_param_1
)
{
	.reg .b32 	%r<2>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<8>;


	ld.param.u64 	%rd1, [_Z4add2PdPKd_param_0];
	ld.param.u64 	%rd2, [_Z4add2PdPKd_param_1];
	cvta.to.global.u64 	%rd3, %rd1;
	cvta.to.global.u64 	%rd4, %rd2;
	mov.u32 	%r1, %tid.x;
	mul.wide.s32 	%rd5, %r1, 8;
	add.s64 	%rd6, %rd4, %rd5;
	ld.global.f64 	%fd1, [%rd6];
	add.s64 	%rd7, %rd3, %rd5;
	ld.global.f64 	%fd2, [%rd7];
	add.f64 	%fd3, %fd1, %fd2;
	st.global.f64 	[%rd7], %fd3;
	ret;
}

	// .globl	_Z9multiply1PKdS0_S0_S0_Pd
.visible .entry _Z9multiply1PKdS0_S0_S0_Pd(
	.param .u64 _Z9multiply1PKdS0_S0_S0_Pd_param_0,
	.param .u64 _Z9multiply1PKdS0_S0_S0_Pd_param_1,
	.param .u64 _Z9multiply1PKdS0_S0_S0_Pd_param_2,
	.param .u64 _Z9multiply1PKdS0_S0_S0_Pd_param_3,
	.param .u64 _Z9multiply1PKdS0_S0_S0_Pd_param_4
)
{
	.reg .b32 	%r<2>;
	.reg .f64 	%fd<9>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd1, [_Z9multiply1PKdS0_S0_S0_Pd_param_0];
	ld.param.u64 	%rd2, [_Z9multiply1PKdS0_S0_S0_Pd_param_1];
	ld.param.u64 	%rd3, [_Z9multiply1PKdS0_S0_S0_Pd_param_2];
	ld.param.u64 	%rd4, [_Z9multiply1PKdS0_S0_S0_Pd_param_3];
	ld.param.u64 	%rd5, [_Z9multiply1PKdS0_S0_S0_Pd_param_4];
	cvta.to.global.u64 	%rd6, %rd5;
	cvta.to.global.u64 	%rd7, %rd1;
	cvta.to.global.u64 	%rd8, %rd2;
	cvta.to.global.u64 	%rd9, %rd3;
	cvta.to.global.u64 	%rd10, %rd4;
	mov.u32 	%r1, %tid.x;
	mul.wide.s32 	%rd11, %r1, 8;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.f64 	%fd1, [%rd12];
	add.s64 	%rd13, %rd9, %rd11;
	ld.global.f64 	%fd2, [%rd13];
	mul.f64 	%fd3, %fd1, %fd2;
	add.s64 	%rd14, %rd8, %rd11;
	ld.global.f64 	%fd4, [%rd14];
	mul.f64 	%fd5, %fd3, %fd4;
	add.s64 	%rd15, %rd7, %rd11;
	ld.global.f64 	%fd6, [%rd15];
	add.s64 	%rd16, %rd6, %rd11;
	ld.global.f64 	%fd7, [%rd16];
	fma.rn.f64 	%fd8, %fd5, %fd6, %fd7;
	st.global.f64 	[%rd16], %fd8;
	ret;
}

	// .globl	_Z14matrixMultiplyPKdS0_Pdi
.visible .entry _Z14matrixMultiplyPKdS0_Pdi(
	.param .u64 _Z14matrixMultiplyPKdS0_Pdi_param_0,
	.param .u64 _Z14matrixMultiplyPKdS0_Pdi_param_1,
	.param .u64 _Z14matrixMultiplyPKdS0_Pdi_param_2,
	.param .u32 _Z14matrixMultiplyPKdS0_Pdi_param_3
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<8>;
	.reg .b32 	%r<35>;
	.reg .f64 	%fd<43>;
	.reg .b64 	%rd<32>;


	ld.param.u64 	%rd7, [_Z14matrixMultiplyPKdS0_Pdi_param_0];
	ld.param.u64 	%rd8, [_Z14matrixMultiplyPKdS0_Pdi_param_1];
	ld.param.u64 	%rd6, [_Z14matrixMultiplyPKdS0_Pdi_param_2];
	ld.param.u32 	%r16, [_Z14matrixMultiplyPKdS0_Pdi_param_3];
	cvta.to.global.u64 	%rd1, %rd8;
	cvta.to.global.u64 	%rd2, %rd7;
	mov.u32 	%r1, %ctaid.y;
	setp.ge.s32	%p1, %r1, %r16;
	mov.u32 	%r2, %ctaid.x;
	setp.ge.s32	%p2, %r2, %r16;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB2_12;

	mul.lo.s32 	%r3, %r1, %r16;
	mov.f64 	%fd42, 0d0000000000000000;
	setp.lt.s32	%p4, %r16, 1;
	@%p4 bra 	BB2_11;

	and.b32  	%r20, %r16, 3;
	mov.f64 	%fd42, 0d0000000000000000;
	mov.u32 	%r32, 0;
	setp.eq.s32	%p5, %r20, 0;
	@%p5 bra 	BB2_8;

	setp.eq.s32	%p6, %r20, 1;
	@%p6 bra 	BB2_7;

	setp.eq.s32	%p7, %r20, 2;
	@%p7 bra 	BB2_6;

	mul.wide.s32 	%rd9, %r3, 8;
	add.s64 	%rd10, %rd2, %rd9;
	mul.wide.s32 	%rd11, %r2, 8;
	add.s64 	%rd12, %rd1, %rd11;
	ld.global.f64 	%fd14, [%rd12];
	ld.global.f64 	%fd15, [%rd10];
	fma.rn.f64 	%fd16, %fd15, %fd14, 0d0000000000000000;
	cvt.rn.f32.f64	%f1, %fd16;
	cvt.f64.f32	%fd42, %f1;
	mov.u32 	%r32, 1;

BB2_6:
	add.s32 	%r22, %r32, %r3;
	mul.wide.s32 	%rd13, %r22, 8;
	add.s64 	%rd14, %rd2, %rd13;
	neg.s32 	%r23, %r32;
	and.b32  	%r24, %r23, %r16;
	add.s32 	%r25, %r24, %r2;
	mul.wide.s32 	%rd15, %r25, 8;
	add.s64 	%rd16, %rd1, %rd15;
	ld.global.f64 	%fd17, [%rd16];
	ld.global.f64 	%fd18, [%rd14];
	fma.rn.f64 	%fd19, %fd18, %fd17, %fd42;
	cvt.rn.f32.f64	%f2, %fd19;
	add.s32 	%r32, %r32, 1;
	cvt.f64.f32	%fd42, %f2;

BB2_7:
	add.s32 	%r26, %r32, %r3;
	mul.wide.s32 	%rd17, %r26, 8;
	add.s64 	%rd18, %rd2, %rd17;
	mad.lo.s32 	%r27, %r32, %r16, %r2;
	mul.wide.s32 	%rd19, %r27, 8;
	add.s64 	%rd20, %rd1, %rd19;
	ld.global.f64 	%fd20, [%rd20];
	ld.global.f64 	%fd21, [%rd18];
	fma.rn.f64 	%fd22, %fd21, %fd20, %fd42;
	cvt.rn.f32.f64	%f3, %fd22;
	add.s32 	%r32, %r32, 1;
	cvt.f64.f32	%fd42, %f3;

BB2_8:
	setp.lt.u32	%p8, %r16, 4;
	@%p8 bra 	BB2_11;

	shl.b32 	%r9, %r16, 2;
	mad.lo.s32 	%r28, %r1, %r16, %r32;
	mul.wide.s32 	%rd21, %r28, 8;
	add.s64 	%rd31, %rd2, %rd21;
	mad.lo.s32 	%r33, %r32, %r16, %r2;
	shl.b32 	%r11, %r16, 3;

BB2_10:
	mul.wide.s32 	%rd22, %r33, 8;
	add.s64 	%rd23, %rd1, %rd22;
	ld.global.f64 	%fd23, [%rd23];
	ld.global.f64 	%fd24, [%rd31];
	fma.rn.f64 	%fd25, %fd24, %fd23, %fd42;
	cvt.rn.f32.f64	%f4, %fd25;
	cvt.f64.f32	%fd26, %f4;
	cvt.s64.s32	%rd24, %r11;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.f64 	%fd27, [%rd25];
	ld.global.f64 	%fd28, [%rd31+8];
	fma.rn.f64 	%fd29, %fd28, %fd27, %fd26;
	cvt.rn.f32.f64	%f5, %fd29;
	cvt.f64.f32	%fd30, %f5;
	add.s64 	%rd26, %rd25, %rd24;
	ld.global.f64 	%fd31, [%rd26];
	ld.global.f64 	%fd32, [%rd31+16];
	fma.rn.f64 	%fd33, %fd32, %fd31, %fd30;
	cvt.rn.f32.f64	%f6, %fd33;
	cvt.f64.f32	%fd34, %f6;
	add.s64 	%rd27, %rd26, %rd24;
	ld.global.f64 	%fd35, [%rd27];
	ld.global.f64 	%fd36, [%rd31+24];
	fma.rn.f64 	%fd37, %fd36, %fd35, %fd34;
	cvt.rn.f32.f64	%f7, %fd37;
	cvt.f64.f32	%fd42, %f7;
	add.s64 	%rd31, %rd31, 32;
	add.s32 	%r33, %r33, %r9;
	add.s32 	%r32, %r32, 4;
	setp.lt.s32	%p9, %r32, %r16;
	@%p9 bra 	BB2_10;

BB2_11:
	cvta.to.global.u64 	%rd28, %rd6;
	add.s32 	%r29, %r3, %r2;
	mul.wide.s32 	%rd29, %r29, 8;
	add.s64 	%rd30, %rd28, %rd29;
	st.global.f64 	[%rd30], %fd42;

BB2_12:
	ret;
}


